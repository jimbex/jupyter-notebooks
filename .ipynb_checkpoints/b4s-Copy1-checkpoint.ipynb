{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2922\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urllib.request.urlopen('http://py4e-data.dr-chuck.net/comments_1072440.html').read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "file = soup.find_all('span')\n",
    "\n",
    "total = 0\n",
    "for d in file:\n",
    "    total += int(d.text)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package bs4:\n",
      "\n",
      "NAME\n",
      "    bs4 - Beautiful Soup Elixir and Tonic - \"The Screen-Scraper's Friend\".\n",
      "\n",
      "DESCRIPTION\n",
      "    http://www.crummy.com/software/BeautifulSoup/\n",
      "    \n",
      "    Beautiful Soup uses a pluggable XML or HTML parser to parse a\n",
      "    (possibly invalid) document into a tree representation. Beautiful Soup\n",
      "    provides methods and Pythonic idioms that make it easy to navigate,\n",
      "    search, and modify the parse tree.\n",
      "    \n",
      "    Beautiful Soup works with Python 2.7 and up. It works better if lxml\n",
      "    and/or html5lib is installed.\n",
      "    \n",
      "    For more than you ever wanted to know about Beautiful Soup, see the\n",
      "    documentation: http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    builder (package)\n",
      "    dammit\n",
      "    diagnose\n",
      "    element\n",
      "    formatter\n",
      "    testing\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    bs4.element.Tag(bs4.element.PageElement)\n",
      "        BeautifulSoup\n",
      "    \n",
      "    class BeautifulSoup(bs4.element.Tag)\n",
      "     |  BeautifulSoup(markup='', features=None, builder=None, parse_only=None, from_encoding=None, exclude_encodings=None, element_classes=None, **kwargs)\n",
      "     |  \n",
      "     |  A data structure representing a parsed HTML or XML document.\n",
      "     |  \n",
      "     |  Most of the methods you'll call on a BeautifulSoup object are inherited from\n",
      "     |  PageElement or Tag.\n",
      "     |  \n",
      "     |  Internally, this class defines the basic interface called by the\n",
      "     |  tree builders when converting an HTML/XML document into a data\n",
      "     |  structure. The interface abstracts away the differences between\n",
      "     |  parsers. To write a new tree builder, you'll need to understand\n",
      "     |  these methods as a whole.\n",
      "     |  \n",
      "     |  These methods will be called by the BeautifulSoup constructor:\n",
      "     |    * reset()\n",
      "     |    * feed(markup)\n",
      "     |  \n",
      "     |  The tree builder may call these methods from its feed() implementation:\n",
      "     |    * handle_starttag(name, attrs) # See note about return value\n",
      "     |    * handle_endtag(name)\n",
      "     |    * handle_data(data) # Appends to the current data node\n",
      "     |    * endData(containerClass) # Ends the current data node\n",
      "     |  \n",
      "     |  No matter how complicated the underlying parser is, you should be\n",
      "     |  able to build a tree using 'start tag' events, 'end tag' events,\n",
      "     |  'data' events, and \"done with data\" events.\n",
      "     |  \n",
      "     |  If you encounter an empty-element tag (aka a self-closing tag,\n",
      "     |  like HTML's <br> tag), call handle_starttag and then\n",
      "     |  handle_endtag.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BeautifulSoup\n",
      "     |      bs4.element.Tag\n",
      "     |      bs4.element.PageElement\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |      Copy a BeautifulSoup object by converting the document to a string and parsing it again.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __init__(self, markup='', features=None, builder=None, parse_only=None, from_encoding=None, exclude_encodings=None, element_classes=None, **kwargs)\n",
      "     |      Constructor.\n",
      "     |      \n",
      "     |      :param markup: A string or a file-like object representing\n",
      "     |       markup to be parsed.\n",
      "     |      \n",
      "     |      :param features: Desirable features of the parser to be\n",
      "     |       used. This may be the name of a specific parser (\"lxml\",\n",
      "     |       \"lxml-xml\", \"html.parser\", or \"html5lib\") or it may be the\n",
      "     |       type of markup to be used (\"html\", \"html5\", \"xml\"). It's\n",
      "     |       recommended that you name a specific parser, so that\n",
      "     |       Beautiful Soup gives you the same results across platforms\n",
      "     |       and virtual environments.\n",
      "     |      \n",
      "     |      :param builder: A TreeBuilder subclass to instantiate (or\n",
      "     |       instance to use) instead of looking one up based on\n",
      "     |       `features`. You only need to use this if you've implemented a\n",
      "     |       custom TreeBuilder.\n",
      "     |      \n",
      "     |      :param parse_only: A SoupStrainer. Only parts of the document\n",
      "     |       matching the SoupStrainer will be considered. This is useful\n",
      "     |       when parsing part of a document that would otherwise be too\n",
      "     |       large to fit into memory.\n",
      "     |      \n",
      "     |      :param from_encoding: A string indicating the encoding of the\n",
      "     |       document to be parsed. Pass this in if Beautiful Soup is\n",
      "     |       guessing wrongly about the document's encoding.\n",
      "     |      \n",
      "     |      :param exclude_encodings: A list of strings indicating\n",
      "     |       encodings known to be wrong. Pass this in if you don't know\n",
      "     |       the document's encoding but you know Beautiful Soup's guess is\n",
      "     |       wrong.\n",
      "     |      \n",
      "     |      :param element_classes: A dictionary mapping BeautifulSoup\n",
      "     |       classes like Tag and NavigableString, to other classes you'd\n",
      "     |       like to be instantiated instead as the parse tree is\n",
      "     |       built. This is useful for subclassing Tag or NavigableString\n",
      "     |       to modify default behavior.\n",
      "     |      \n",
      "     |      :param kwargs: For backwards compatibility purposes, the\n",
      "     |       constructor accepts certain keyword arguments used in\n",
      "     |       Beautiful Soup 3. None of these arguments do anything in\n",
      "     |       Beautiful Soup 4; they will result in a warning and then be\n",
      "     |       ignored.\n",
      "     |       \n",
      "     |       Apart from this, any keyword arguments passed into the\n",
      "     |       BeautifulSoup constructor are propagated to the TreeBuilder\n",
      "     |       constructor. This makes it possible to configure a\n",
      "     |       TreeBuilder by passing in arguments, not just by saying which\n",
      "     |       one to use.\n",
      "     |  \n",
      "     |  decode(self, pretty_print=False, eventual_encoding='utf-8', formatter='minimal')\n",
      "     |      Returns a string or Unicode representation of the parse tree\n",
      "     |          as an HTML or XML document.\n",
      "     |      \n",
      "     |      :param pretty_print: If this is True, indentation will be used to\n",
      "     |          make the document more readable.\n",
      "     |      :param eventual_encoding: The encoding of the final document.\n",
      "     |          If this is None, the document will be a Unicode string.\n",
      "     |  \n",
      "     |  endData(self, containerClass=None)\n",
      "     |      Method called by the TreeBuilder when the end of a data segment\n",
      "     |      occurs.\n",
      "     |  \n",
      "     |  handle_data(self, data)\n",
      "     |      Called by the tree builder when a chunk of textual data is encountered.\n",
      "     |  \n",
      "     |  handle_endtag(self, name, nsprefix=None)\n",
      "     |      Called by the tree builder when an ending tag is encountered.\n",
      "     |      \n",
      "     |      :param name: Name of the tag.\n",
      "     |      :param nsprefix: Namespace prefix for the tag.\n",
      "     |  \n",
      "     |  handle_starttag(self, name, namespace, nsprefix, attrs, sourceline=None, sourcepos=None)\n",
      "     |      Called by the tree builder when a new tag is encountered.\n",
      "     |      \n",
      "     |      :param name: Name of the tag.\n",
      "     |      :param nsprefix: Namespace prefix for the tag.\n",
      "     |      :param attrs: A dictionary of attribute values.\n",
      "     |      :param sourceline: The line number where this tag was found in its\n",
      "     |          source document.\n",
      "     |      :param sourcepos: The character position within `sourceline` where this\n",
      "     |          tag was found.\n",
      "     |      \n",
      "     |      If this method returns None, the tag was rejected by an active\n",
      "     |      SoupStrainer. You should proceed as if the tag had not occurred\n",
      "     |      in the document. For instance, if this was a self-closing tag,\n",
      "     |      don't call handle_endtag.\n",
      "     |  \n",
      "     |  insert_after(self, successor)\n",
      "     |      This method is part of the PageElement API, but `BeautifulSoup` doesn't implement\n",
      "     |      it because there is nothing before or after it in the parse tree.\n",
      "     |  \n",
      "     |  insert_before(self, successor)\n",
      "     |      This method is part of the PageElement API, but `BeautifulSoup` doesn't implement\n",
      "     |      it because there is nothing before or after it in the parse tree.\n",
      "     |  \n",
      "     |  new_string(self, s, subclass=None)\n",
      "     |      Create a new NavigableString associated with this BeautifulSoup\n",
      "     |      object.\n",
      "     |  \n",
      "     |  new_tag(self, name, namespace=None, nsprefix=None, attrs={}, sourceline=None, sourcepos=None, **kwattrs)\n",
      "     |      Create a new Tag associated with this BeautifulSoup object.\n",
      "     |      \n",
      "     |      :param name: The name of the new Tag.\n",
      "     |      :param namespace: The URI of the new Tag's XML namespace, if any.\n",
      "     |      :param prefix: The prefix for the new Tag's XML namespace, if any.\n",
      "     |      :param attrs: A dictionary of this Tag's attribute values; can\n",
      "     |          be used instead of `kwattrs` for attributes like 'class'\n",
      "     |          that are reserved words in Python.\n",
      "     |      :param sourceline: The line number where this tag was\n",
      "     |          (purportedly) found in its source document.\n",
      "     |      :param sourcepos: The character position within `sourceline` where this\n",
      "     |          tag was (purportedly) found.\n",
      "     |      :param kwattrs: Keyword arguments for the new Tag's attribute values.\n",
      "     |  \n",
      "     |  object_was_parsed(self, o, parent=None, most_recent_element=None)\n",
      "     |      Method called by the TreeBuilder to integrate an object into the parse tree.\n",
      "     |  \n",
      "     |  popTag(self)\n",
      "     |      Internal method called by _popToTag when a tag is closed.\n",
      "     |  \n",
      "     |  pushTag(self, tag)\n",
      "     |      Internal method called by handle_starttag when a tag is opened.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Reset this object to a state as though it had never parsed any\n",
      "     |      markup.\n",
      "     |  \n",
      "     |  string_container(self, base_class=None)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ASCII_SPACES = ' \\n\\t\\x0c\\r'\n",
      "     |  \n",
      "     |  DEFAULT_BUILDER_FEATURES = ['html', 'fast']\n",
      "     |  \n",
      "     |  NO_PARSER_SPECIFIED_WARNING = 'No parser was explicitly specified, so ...\n",
      "     |  \n",
      "     |  ROOT_TAG_NAME = '[document]'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      A tag is non-None even if it has no contents.\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwargs)\n",
      "     |      Calling a Tag like a function is the same as calling its\n",
      "     |      find_all() method. Eg. tag('a') returns a list of all the A tags\n",
      "     |      found within this tag.\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Deleting tag[key] deletes all 'key' attributes for the tag.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns true iff this Tag has the same name, the same attributes,\n",
      "     |      and the same contents (recursively) as `other`.\n",
      "     |  \n",
      "     |  __getattr__(self, tag)\n",
      "     |      Calling tag.subtag is the same as calling tag.find(name=\"subtag\")\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      tag[key] returns the value of the 'key' attribute for the Tag,\n",
      "     |      and throws an exception if it's not there.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterating over a Tag iterates over its contents.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      The length of a Tag is the length of its list of contents.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns true iff this Tag is not identical to `other`,\n",
      "     |      as defined in __eq__.\n",
      "     |  \n",
      "     |  __repr__ = __unicode__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Setting tag[key] sets the value of the 'key' attribute for the\n",
      "     |      tag.\n",
      "     |  \n",
      "     |  __str__ = __unicode__(self)\n",
      "     |  \n",
      "     |  __unicode__(self)\n",
      "     |      Renders this PageElement as a Unicode string.\n",
      "     |  \n",
      "     |  childGenerator(self)\n",
      "     |      Deprecated generator.\n",
      "     |  \n",
      "     |  clear(self, decompose=False)\n",
      "     |      Wipe out all children of this PageElement by calling extract()\n",
      "     |         on them.\n",
      "     |      \n",
      "     |      :param decompose: If this is True, decompose() (a more\n",
      "     |          destructive method) will be called instead of extract().\n",
      "     |  \n",
      "     |  decode_contents(self, indent_level=None, eventual_encoding='utf-8', formatter='minimal')\n",
      "     |      Renders the contents of this tag as a Unicode string.\n",
      "     |      \n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many spaces. Used internally in\n",
      "     |         recursive calls while pretty-printing.\n",
      "     |      \n",
      "     |      :param eventual_encoding: The tag is destined to be\n",
      "     |         encoded into this encoding. decode_contents() is _not_\n",
      "     |         responsible for performing that encoding. This information\n",
      "     |         is passed in so that it can be substituted in if the\n",
      "     |         document contains a <META> tag that mentions the document's\n",
      "     |         encoding.\n",
      "     |      \n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard Formatters.\n",
      "     |  \n",
      "     |  decompose(self)\n",
      "     |      Recursively destroys this PageElement and its children.\n",
      "     |      \n",
      "     |      This element will be removed from the tree and wiped out; so\n",
      "     |      will everything beneath it.\n",
      "     |      \n",
      "     |      The behavior of a decomposed PageElement is undefined and you\n",
      "     |      should never use one for anything, but if you need to _check_\n",
      "     |      whether an element has been decomposed, you can use the\n",
      "     |      `decomposed` property.\n",
      "     |  \n",
      "     |  encode(self, encoding='utf-8', indent_level=None, formatter='minimal', errors='xmlcharrefreplace')\n",
      "     |      Render a bytestring representation of this PageElement and its\n",
      "     |      contents.\n",
      "     |      \n",
      "     |      :param encoding: The destination encoding.\n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |          indented this many spaces. Used internally in\n",
      "     |          recursive calls while pretty-printing.\n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard formatters.\n",
      "     |      :param errors: An error handling strategy such as\n",
      "     |          'xmlcharrefreplace'. This value is passed along into\n",
      "     |          encode() and its value should be one of the constants\n",
      "     |          defined by Python.\n",
      "     |      :return: A bytestring.\n",
      "     |  \n",
      "     |  encode_contents(self, indent_level=None, encoding='utf-8', formatter='minimal')\n",
      "     |      Renders the contents of this PageElement as a bytestring.\n",
      "     |      \n",
      "     |      :param indent_level: Each line of the rendering will be\n",
      "     |         indented this many spaces. Used internally in\n",
      "     |         recursive calls while pretty-printing.\n",
      "     |      \n",
      "     |      :param eventual_encoding: The bytestring will be in this encoding.\n",
      "     |      \n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard Formatters.\n",
      "     |      \n",
      "     |      :return: A bytestring.\n",
      "     |  \n",
      "     |  find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)\n",
      "     |      Look in the children of this PageElement and find the first\n",
      "     |      PageElement that matches the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param recursive: If this is True, find() will perform a\n",
      "     |          recursive search of this PageElement's children. Otherwise,\n",
      "     |          only the direct children will be considered.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  findAll = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findChild = find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)\n",
      "     |  \n",
      "     |  findChildren = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      "     |      Look in the children of this PageElement and find all\n",
      "     |      PageElements that match the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param recursive: If this is True, find_all() will perform a\n",
      "     |          recursive search of this PageElement's children. Otherwise,\n",
      "     |          only the direct children will be considered.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      Returns the value of the 'key' attribute for the tag, or\n",
      "     |      the value given for 'default' if it doesn't have that\n",
      "     |      attribute.\n",
      "     |  \n",
      "     |  getText = get_text(self, separator='', strip=False, types=(<class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'>))\n",
      "     |  \n",
      "     |  get_attribute_list(self, key, default=None)\n",
      "     |      The same as get(), but always returns a list.\n",
      "     |      \n",
      "     |      :param key: The attribute to look for.\n",
      "     |      :param default: Use this value if the attribute is not present\n",
      "     |          on this PageElement.\n",
      "     |      :return: A list of values, probably containing only a single\n",
      "     |          value.\n",
      "     |  \n",
      "     |  get_text(self, separator='', strip=False, types=(<class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'>))\n",
      "     |      Get all child strings, concatenated using the given separator.\n",
      "     |      \n",
      "     |      :param separator: Strings will be concatenated using this separator.\n",
      "     |      \n",
      "     |      :param strip: If True, strings will be stripped before being\n",
      "     |          concatenated.\n",
      "     |      \n",
      "     |      :types: A tuple of NavigableString subclasses. Any strings of\n",
      "     |          a subclass not found in this list will be ignored. By\n",
      "     |          default, this means only NavigableString and CData objects\n",
      "     |          will be considered. So no comments, processing instructions,\n",
      "     |          stylesheets, etc.\n",
      "     |      \n",
      "     |      :return: A string.\n",
      "     |  \n",
      "     |  has_attr(self, key)\n",
      "     |      Does this PageElement have an attribute with the given name?\n",
      "     |  \n",
      "     |  has_key(self, key)\n",
      "     |      Deprecated method. This was kind of misleading because has_key()\n",
      "     |      (attributes) was different from __in__ (contents).\n",
      "     |      \n",
      "     |      has_key() is gone in Python 3, anyway.\n",
      "     |  \n",
      "     |  index(self, element)\n",
      "     |      Find the index of a child by identity, not value.\n",
      "     |      \n",
      "     |      Avoids issues with tag.contents.index(element) getting the\n",
      "     |      index of equal elements.\n",
      "     |      \n",
      "     |      :param element: Look for this PageElement in `self.contents`.\n",
      "     |  \n",
      "     |  prettify(self, encoding=None, formatter='minimal')\n",
      "     |      Pretty-print this PageElement as a string.\n",
      "     |      \n",
      "     |      :param encoding: The eventual encoding of the string. If this is None,\n",
      "     |          a Unicode string will be returned.\n",
      "     |      :param formatter: A Formatter object, or a string naming one of\n",
      "     |          the standard formatters.\n",
      "     |      :return: A Unicode string (if encoding==None) or a bytestring \n",
      "     |          (otherwise).\n",
      "     |  \n",
      "     |  recursiveChildGenerator(self)\n",
      "     |      Deprecated generator.\n",
      "     |  \n",
      "     |  renderContents(self, encoding='utf-8', prettyPrint=False, indentLevel=0)\n",
      "     |      Deprecated method for BS3 compatibility.\n",
      "     |  \n",
      "     |  select(self, selector, namespaces=None, limit=None, **kwargs)\n",
      "     |      Perform a CSS selection operation on the current element.\n",
      "     |      \n",
      "     |      This uses the SoupSieve library.\n",
      "     |      \n",
      "     |      :param selector: A string containing a CSS selector.\n",
      "     |      \n",
      "     |      :param namespaces: A dictionary mapping namespace prefixes\n",
      "     |         used in the CSS selector to namespace URIs. By default,\n",
      "     |         Beautiful Soup will use the prefixes it encountered while\n",
      "     |         parsing the document.\n",
      "     |      \n",
      "     |      :param limit: After finding this number of results, stop looking.\n",
      "     |      \n",
      "     |      :param kwargs: Keyword arguments to be passed into SoupSieve's \n",
      "     |         soupsieve.select() method.\n",
      "     |      \n",
      "     |      :return: A ResultSet of Tags.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  select_one(self, selector, namespaces=None, **kwargs)\n",
      "     |      Perform a CSS selection operation on the current element.\n",
      "     |      \n",
      "     |      :param selector: A CSS selector.\n",
      "     |      \n",
      "     |      :param namespaces: A dictionary mapping namespace prefixes\n",
      "     |         used in the CSS selector to namespace URIs. By default,\n",
      "     |         Beautiful Soup will use the prefixes it encountered while\n",
      "     |         parsing the document.\n",
      "     |      \n",
      "     |      :param kwargs: Keyword arguments to be passed into SoupSieve's \n",
      "     |         soupsieve.select() method.\n",
      "     |      \n",
      "     |      :return: A Tag.\n",
      "     |      :rtype: bs4.element.Tag\n",
      "     |  \n",
      "     |  smooth(self)\n",
      "     |      Smooth out this element's children by consolidating consecutive\n",
      "     |      strings.\n",
      "     |      \n",
      "     |      This makes pretty-printed output look more natural following a\n",
      "     |      lot of operations that modified the tree.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from bs4.element.Tag:\n",
      "     |  \n",
      "     |  children\n",
      "     |      Iterate over all direct children of this PageElement.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  descendants\n",
      "     |      Iterate over all children of this PageElement in a\n",
      "     |      breadth-first sequence.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  isSelfClosing\n",
      "     |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      "     |      \n",
      "     |      A tag that has contents is never an empty-element tag.\n",
      "     |      \n",
      "     |      A tag that has no contents may or may not be an empty-element\n",
      "     |      tag. It depends on the builder used to create the tag. If the\n",
      "     |      builder has a designated list of empty-element tags, then only\n",
      "     |      a tag whose name shows up in that list is considered an\n",
      "     |      empty-element tag.\n",
      "     |      \n",
      "     |      If the builder has no designated list of empty-element tags,\n",
      "     |      then any tag with no contents is an empty-element tag.\n",
      "     |  \n",
      "     |  is_empty_element\n",
      "     |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      "     |      \n",
      "     |      A tag that has contents is never an empty-element tag.\n",
      "     |      \n",
      "     |      A tag that has no contents may or may not be an empty-element\n",
      "     |      tag. It depends on the builder used to create the tag. If the\n",
      "     |      builder has a designated list of empty-element tags, then only\n",
      "     |      a tag whose name shows up in that list is considered an\n",
      "     |      empty-element tag.\n",
      "     |      \n",
      "     |      If the builder has no designated list of empty-element tags,\n",
      "     |      then any tag with no contents is an empty-element tag.\n",
      "     |  \n",
      "     |  parserClass\n",
      "     |  \n",
      "     |  string\n",
      "     |      Convenience property to get the single string within this\n",
      "     |      PageElement.\n",
      "     |      \n",
      "     |      TODO It might make sense to have NavigableString.string return\n",
      "     |      itself.\n",
      "     |      \n",
      "     |      :return: If this element has a single string child, return\n",
      "     |       value is that string. If this element has one child tag,\n",
      "     |       return value is the 'string' attribute of the child tag,\n",
      "     |       recursively. If this element is itself a string, has no\n",
      "     |       children, or has more than one child, return value is None.\n",
      "     |  \n",
      "     |  strings\n",
      "     |      Yield all strings of certain classes, possibly stripping them.\n",
      "     |      \n",
      "     |      :param strip: If True, all strings will be stripped before being\n",
      "     |          yielded.\n",
      "     |      \n",
      "     |      :types: A tuple of NavigableString subclasses. Any strings of\n",
      "     |          a subclass not found in this list will be ignored. By\n",
      "     |          default, this means only NavigableString and CData objects\n",
      "     |          will be considered. So no comments, processing instructions,\n",
      "     |          etc.\n",
      "     |      \n",
      "     |      :yield: A sequence of strings.\n",
      "     |  \n",
      "     |  stripped_strings\n",
      "     |      Yield all strings in the document, stripping them first.\n",
      "     |      \n",
      "     |      :yield: A sequence of stripped strings.\n",
      "     |  \n",
      "     |  text\n",
      "     |      Get all child strings, concatenated using the given separator.\n",
      "     |      \n",
      "     |      :param separator: Strings will be concatenated using this separator.\n",
      "     |      \n",
      "     |      :param strip: If True, strings will be stripped before being\n",
      "     |          concatenated.\n",
      "     |      \n",
      "     |      :types: A tuple of NavigableString subclasses. Any strings of\n",
      "     |          a subclass not found in this list will be ignored. By\n",
      "     |          default, this means only NavigableString and CData objects\n",
      "     |          will be considered. So no comments, processing instructions,\n",
      "     |          stylesheets, etc.\n",
      "     |      \n",
      "     |      :return: A string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  append(self, tag)\n",
      "     |      Appends the given PageElement to the contents of this one.\n",
      "     |      \n",
      "     |      :param tag: A PageElement.\n",
      "     |  \n",
      "     |  extend(self, tags)\n",
      "     |      Appends the given PageElements to this one's contents.\n",
      "     |      \n",
      "     |      :param tags: A list of PageElements.\n",
      "     |  \n",
      "     |  extract(self, _self_index=None)\n",
      "     |      Destructively rips this element out of the tree.\n",
      "     |      \n",
      "     |      :param _self_index: The location of this element in its parent's\n",
      "     |         .contents, if known. Passing this in allows for a performance\n",
      "     |         optimization.\n",
      "     |      \n",
      "     |      :return: `self`, no longer part of the tree.\n",
      "     |  \n",
      "     |  fetchNextSiblings = find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  fetchParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  fetchPrevious = find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  fetchPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findAllNext = find_all_next(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findAllPrevious = find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findNext = find_next(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |  \n",
      "     |  findNextSibling = find_next_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |  \n",
      "     |  findNextSiblings = find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findParent = find_parent(self, name=None, attrs={}, **kwargs)\n",
      "     |  \n",
      "     |  findParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  findPrevious = find_previous(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |  \n",
      "     |  findPreviousSibling = find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |  \n",
      "     |  findPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |  \n",
      "     |  find_all_next(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Find all PageElements that match the given criteria and appear\n",
      "     |      later in the document than this PageElement.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet containing PageElements.\n",
      "     |  \n",
      "     |  find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Look backwards in the document from this PageElement and find all\n",
      "     |      PageElements that match the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  find_next(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Find the first PageElement that matches the given criteria and\n",
      "     |      appears later in the document than this PageElement.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_next_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Find the closest sibling to this PageElement that matches the\n",
      "     |      given criteria and appears later in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the\n",
      "     |      online documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Find all siblings of this PageElement that match the given criteria\n",
      "     |      and appear later in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  find_parent(self, name=None, attrs={}, **kwargs)\n",
      "     |      Find the closest parent of this PageElement that matches the given\n",
      "     |      criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      "     |      Find all parents of this PageElement that match the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_previous(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Look backwards in the document from this PageElement and find the\n",
      "     |      first PageElement that matches the given criteria.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      "     |      Returns the closest sibling to this PageElement that matches the\n",
      "     |      given criteria and appears earlier in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      "     |      Returns all siblings to this PageElement that match the\n",
      "     |      given criteria and appear earlier in the document.\n",
      "     |      \n",
      "     |      All find_* methods take a common set of arguments. See the online\n",
      "     |      documentation for detailed explanations.\n",
      "     |      \n",
      "     |      :param name: A filter on tag name.\n",
      "     |      :param attrs: A dictionary of filters on attribute values.\n",
      "     |      :param text: A filter for a NavigableString with specific text.\n",
      "     |      :param limit: Stop looking after finding this many results.\n",
      "     |      :kwargs: A dictionary of filters on attribute values.\n",
      "     |      :return: A ResultSet of PageElements.\n",
      "     |      :rtype: bs4.element.ResultSet\n",
      "     |  \n",
      "     |  format_string(self, s, formatter)\n",
      "     |      Format the given string using the given formatter.\n",
      "     |      \n",
      "     |      :param s: A string.\n",
      "     |      :param formatter: A Formatter object, or a string naming one of the standard formatters.\n",
      "     |  \n",
      "     |  formatter_for_name(self, formatter)\n",
      "     |      Look up or create a Formatter for the given identifier,\n",
      "     |      if necessary.\n",
      "     |      \n",
      "     |      :param formatter: Can be a Formatter object (used as-is), a\n",
      "     |          function (used as the entity substitution hook for an\n",
      "     |          XMLFormatter or HTMLFormatter), or a string (used to look\n",
      "     |          up an XMLFormatter or HTMLFormatter in the appropriate\n",
      "     |          registry.\n",
      "     |  \n",
      "     |  insert(self, position, new_child)\n",
      "     |      Insert a new PageElement in the list of this PageElement's children.\n",
      "     |      \n",
      "     |      This works the same way as `list.insert`.\n",
      "     |      \n",
      "     |      :param position: The numeric position that should be occupied\n",
      "     |         in `self.children` by the new PageElement. \n",
      "     |      :param new_child: A PageElement.\n",
      "     |  \n",
      "     |  nextGenerator(self)\n",
      "     |      # Old non-property versions of the generators, for backwards\n",
      "     |      # compatibility with BS3.\n",
      "     |  \n",
      "     |  nextSiblingGenerator(self)\n",
      "     |  \n",
      "     |  parentGenerator(self)\n",
      "     |  \n",
      "     |  previousGenerator(self)\n",
      "     |  \n",
      "     |  previousSiblingGenerator(self)\n",
      "     |  \n",
      "     |  replaceWith = replace_with(self, replace_with)\n",
      "     |  \n",
      "     |  replaceWithChildren = unwrap(self)\n",
      "     |  \n",
      "     |  replace_with(self, replace_with)\n",
      "     |      Replace this PageElement with another one, keeping the rest of the\n",
      "     |      tree the same.\n",
      "     |      \n",
      "     |      :param replace_with: A PageElement.\n",
      "     |      :return: `self`, no longer part of the tree.\n",
      "     |  \n",
      "     |  replace_with_children = unwrap(self)\n",
      "     |  \n",
      "     |  setup(self, parent=None, previous_element=None, next_element=None, previous_sibling=None, next_sibling=None)\n",
      "     |      Sets up the initial relations between this element and\n",
      "     |      other elements.\n",
      "     |      \n",
      "     |      :param parent: The parent of this element.\n",
      "     |      \n",
      "     |      :param previous_element: The element parsed immediately before\n",
      "     |          this one.\n",
      "     |      \n",
      "     |      :param next_element: The element parsed immediately before\n",
      "     |          this one.\n",
      "     |      \n",
      "     |      :param previous_sibling: The most recently encountered element\n",
      "     |          on the same level of the parse tree as this one.\n",
      "     |      \n",
      "     |      :param previous_sibling: The next element to be encountered\n",
      "     |          on the same level of the parse tree as this one.\n",
      "     |  \n",
      "     |  unwrap(self)\n",
      "     |      Replace this PageElement with its contents.\n",
      "     |      \n",
      "     |      :return: `self`, no longer part of the tree.\n",
      "     |  \n",
      "     |  wrap(self, wrap_inside)\n",
      "     |      Wrap this PageElement inside another one.\n",
      "     |      \n",
      "     |      :param wrap_inside: A PageElement.\n",
      "     |      :return: `wrap_inside`, occupying the position in the tree that used\n",
      "     |         to be occupied by `self`, and with `self` inside it.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from bs4.element.PageElement:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  decomposed\n",
      "     |      Check whether a PageElement has been decomposed.\n",
      "     |      \n",
      "     |      :rtype: bool\n",
      "     |  \n",
      "     |  next\n",
      "     |      The PageElement, if any, that was parsed just after this one.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  nextSibling\n",
      "     |  \n",
      "     |  next_elements\n",
      "     |      All PageElements that were parsed after this one.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  next_siblings\n",
      "     |      All PageElements that are siblings of this one but were parsed\n",
      "     |      later.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  parents\n",
      "     |      All PageElements that are parents of this PageElement.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  previous\n",
      "     |      The PageElement, if any, that was parsed just before this one.\n",
      "     |      \n",
      "     |      :return: A PageElement.\n",
      "     |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      "     |  \n",
      "     |  previousSibling\n",
      "     |  \n",
      "     |  previous_elements\n",
      "     |      All PageElements that were parsed before this one.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "     |  \n",
      "     |  previous_siblings\n",
      "     |      All PageElements that are siblings of this one but were parsed\n",
      "     |      earlier.\n",
      "     |      \n",
      "     |      :yield: A sequence of PageElements.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BeautifulSoup']\n",
      "    __copyright__ = 'Copyright (c) 2004-2020 Leonard Richardson'\n",
      "    __license__ = 'MIT'\n",
      "\n",
      "VERSION\n",
      "    4.9.1\n",
      "\n",
      "AUTHOR\n",
      "    Leonard Richardson (leonardr@segfault.org)\n",
      "\n",
      "FILE\n",
      "    c:\\users\\user\\anaconda3\\lib\\site-packages\\bs4\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "help(bs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://py4e-data.dr-chuck.net/known_by_Chioma.html\">Chioma</a>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urllib.request.urlopen('http://py4e-data.dr-chuck.net/known_by_Rhiana.html').read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "file = soup.find('a')\n",
    "for x in file:\n",
    "    print(x.get('href'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Welcome to the comments assignment from www.py4e.com</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>This file contains the actual data for your assignment - good luck!</h1>\n",
      "\n",
      "<table border=\"2\">\n",
      "<tr>\n",
      "<td>Name</td><td>Comments</td>\n",
      "</tr>\n",
      "<tr><td>Hafswa</td><td><span class=\"comments\">99</span></td></tr>\n",
      "<tr><td>Machlan</td><td><span class=\"comments\">97</span></td></tr>\n",
      "<tr><td>Ashtyn</td><td><span class=\"comments\">93</span></td></tr>\n",
      "<tr><td>Leithen</td><td><span class=\"comments\">93</span></td></tr>\n",
      "<tr><td>Bully</td><td><span class=\"comments\">89</span></td></tr>\n",
      "<tr><td>Katerina</td><td><span class=\"comments\">88</span></td></tr>\n",
      "<tr><td>Komal</td><td><span class=\"comments\">88</span></td></tr>\n",
      "<tr><td>Colvin</td><td><span class=\"comments\">88</span></td></tr>\n",
      "<tr><td>Nelson</td><td><span class=\"comments\">86</span></td></tr>\n",
      "<tr><td>Eila</td><td><span class=\"comments\">86</span></td></tr>\n",
      "<tr><td>Cavan</td><td><span class=\"comments\">86</span></td></tr>\n",
      "<tr><td>Grant</td><td><span class=\"comments\">86</span></td></tr>\n",
      "<tr><td>Chase</td><td><span class=\"comments\">85</span></td></tr>\n",
      "<tr><td>Melissa</td><td><span class=\"comments\">82</span></td></tr>\n",
      "<tr><td>Bryan</td><td><span class=\"comments\">82</span></td></tr>\n",
      "<tr><td>Santino</td><td><span class=\"comments\">77</span></td></tr>\n",
      "<tr><td>Keziah</td><td><span class=\"comments\">75</span></td></tr>\n",
      "<tr><td>Kathryn</td><td><span class=\"comments\">75</span></td></tr>\n",
      "<tr><td>Cherith</td><td><span class=\"comments\">74</span></td></tr>\n",
      "<tr><td>Haghdann</td><td><span class=\"comments\">73</span></td></tr>\n",
      "<tr><td>Annelise</td><td><span class=\"comments\">73</span></td></tr>\n",
      "<tr><td>Ceren</td><td><span class=\"comments\">69</span></td></tr>\n",
      "<tr><td>Riana</td><td><span class=\"comments\">68</span></td></tr>\n",
      "<tr><td>Hibah</td><td><span class=\"comments\">66</span></td></tr>\n",
      "<tr><td>Taiwo</td><td><span class=\"comments\">63</span></td></tr>\n",
      "<tr><td>Dev</td><td><span class=\"comments\">59</span></td></tr>\n",
      "<tr><td>Trudy</td><td><span class=\"comments\">58</span></td></tr>\n",
      "<tr><td>Sunny</td><td><span class=\"comments\">58</span></td></tr>\n",
      "<tr><td>Strachan</td><td><span class=\"comments\">56</span></td></tr>\n",
      "<tr><td>Micaila</td><td><span class=\"comments\">53</span></td></tr>\n",
      "<tr><td>Charlene</td><td><span class=\"comments\">53</span></td></tr>\n",
      "<tr><td>Zuhrah</td><td><span class=\"comments\">52</span></td></tr>\n",
      "<tr><td>Modoulamin</td><td><span class=\"comments\">51</span></td></tr>\n",
      "<tr><td>Eireann</td><td><span class=\"comments\">46</span></td></tr>\n",
      "<tr><td>Keryis</td><td><span class=\"comments\">46</span></td></tr>\n",
      "<tr><td>Emilyjo</td><td><span class=\"comments\">43</span></td></tr>\n",
      "<tr><td>Zacharias</td><td><span class=\"comments\">41</span></td></tr>\n",
      "<tr><td>Cameryn</td><td><span class=\"comments\">37</span></td></tr>\n",
      "<tr><td>Kayda</td><td><span class=\"comments\">34</span></td></tr>\n",
      "<tr><td>Ifrah</td><td><span class=\"comments\">31</span></td></tr>\n",
      "<tr><td>Paige</td><td><span class=\"comments\">30</span></td></tr>\n",
      "<tr><td>Cassieleigh</td><td><span class=\"comments\">27</span></td></tr>\n",
      "<tr><td>Jaymi</td><td><span class=\"comments\">25</span></td></tr>\n",
      "<tr><td>Harriet</td><td><span class=\"comments\">19</span></td></tr>\n",
      "<tr><td>Megha</td><td><span class=\"comments\">19</span></td></tr>\n",
      "<tr><td>Coban</td><td><span class=\"comments\">17</span></td></tr>\n",
      "<tr><td>Madiha</td><td><span class=\"comments\">12</span></td></tr>\n",
      "<tr><td>Caidy</td><td><span class=\"comments\">9</span></td></tr>\n",
      "<tr><td>Daegan</td><td><span class=\"comments\">4</span></td></tr>\n",
      "<tr><td>Kayah</td><td><span class=\"comments\">1</span></td></tr>\n",
      "</table>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://py4e-data.dr-chuck.net/comments_1072440.html')\n",
    "\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "store = []\n",
    "\n",
    "html = urllib.request.urlopen(' http://py4e-data.dr-chuck.net/known_by_Rhiana.html').read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "count = 1\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    store.append(tag.get('href', None))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6f5fabd7146e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'store' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    html = urllib.request.urlopen(store[17]).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    count = 1\n",
    "    tags = soup('a')\n",
    "    store.clear()\n",
    "    for tag in tags:\n",
    "        store.append(tag.get('href', None))\n",
    "print(store[17])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://py4e-data.dr-chuck.net/known_by_Marybeth.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Conlin.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Kyhran.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Janna.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Sana.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Sandra.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Flint.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Roslyn.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Tessa.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Maxie.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Olympia.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Rayhan.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Asrar.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Camren.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Jessica.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Yann.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Hania.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Meah.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shauni.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Cilla.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Layton.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Annalicia.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Madeeha.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Bayley.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Johnathan.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Keeyra.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Lancelot.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Maison.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Adain.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Lauchlan.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Maxwell.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Eubh.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Sharlyn.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Qi.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Zella.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shanea.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Jaimie.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Kellan.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Derron.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Ayleigh.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Hiro.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Oluwatosin.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Hema.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shiraz.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Taya.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Beatrice.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Rhya.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Kacper.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Ryese.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Prasheeta.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Rishi.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Rennie.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Afrina.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Sorrel.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Emilylee.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Aneshia.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Holli.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Imman.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Zenab.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Gil.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Kati.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Marysia.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Martyna.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Caedyn.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Raghida.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Kaidyn.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Adelaide.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_McKade.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shelby.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Saiba.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Mea.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Devlyn.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Rayane.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Tobias.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Linton.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shiza.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Telise.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Aphra.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Pavit.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shaurya.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Kareem.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Mailli.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Micheal.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Levy.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Mohammad.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Tara.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Keayn.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Cieran.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Harish.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Japjeet.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Tokunbo.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Lorin.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Lilias.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Reggie.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Apisai.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Peni.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Emilyann.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Abar.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Umair.html',\n",
       " 'http://py4e-data.dr-chuck.net/known_by_Shafia.html']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://py4e-data.dr-chuck.net/known_by_Shayaan.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Mitzi.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Blythe.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Andreas.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Argyle.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Cobi.html\n",
      "http://py4e-data.dr-chuck.net/known_by_Meah.html\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "address = 'http://py4e-data.dr-chuck.net/known_by_Rhiana.html'\n",
    "\n",
    "n = 0\n",
    "\n",
    "x = 0\n",
    "\n",
    "while n < 7:\n",
    "    html = urllib.request.urlopen(address).read()\n",
    "    soup = BeautifulSoup(html)\n",
    "    tags = soup('a')\n",
    "    for link in tags:\n",
    "        x = x + 1\n",
    "        if x == 18:\n",
    "            address = link.get('href', None)\n",
    "            print(address)\n",
    "            x = 0\n",
    "            break\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xml.etree.ElementTree.Element"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "data = '''\n",
    "    <Person>\n",
    "    <name>basit</name>\n",
    "    <age>25</age>\n",
    "    <id>101</id>\n",
    "    </Person>\n",
    "'''\n",
    "\n",
    "tree = ET.fromstring(data)\n",
    "print('Name: ', tree.find('name').get('type'))\n",
    "type(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fb5c3738e10f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "data = []\n",
    "\n",
    "html = urllib.request.urlopen(' http://py4e-data.dr-chuck.net/comments_1072442.xml')\n",
    "\n",
    "data = html.read()\n",
    "tree = ET.fromstring(data)\n",
    "counts = tree.findall('.//count')\n",
    "for i in range(0,len(counts)):  \n",
    "    tot += int(counts[i].text) \n",
    "tot\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a location: http://py4e-data.dr-chuck.net/comments_1072442.xml\n",
      "Retrieved:  4205 characters\n",
      "Sum:  2727\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET  \n",
    "tot = 0  \n",
    "url = input(\"Enter a location: \")  \n",
    "pg = urllib.request.urlopen(url)\n",
    "data = pg.read()  \n",
    "tree = ET.fromstring(data)  \n",
    "counts = tree.findall('.//count')  \n",
    "for i in range(0,len(counts)):  \n",
    "    tot += int(counts[i].text)  \n",
    "print('Retrieved: ', len(data), 'characters')\n",
    "print('Sum: ', tot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "http://aws.amazon.com/what-is-cloud-computing\n",
      "http://commoncrawl.org/terms-of-use/\n",
      "http://commoncrawl.org/the-data/get-started/\n",
      "http://commoncrawl.org/\n",
      "https://registry.opendata.aws?search=managedBy:common crawl\n",
      "http://commoncrawl.org/connect/contact-us/\n",
      "https://towardsdatascience.com/large-scale-graph-mining-with-spark-750995050656\n",
      "https://github.com/wsuen/pygotham2018_graphmining\n",
      "https://arxiv.org/abs/1802.06893\n",
      "https://fasttext.cc/docs/en/crawl-vectors.html\n",
      "https://wwwdb.inf.tu-dresden.de/research-projects/dresden-web-table-corpus/\n",
      "https://wwwdb.inf.tu-dresden.de/\n",
      "http://commoncrawl.org/2018/03/index-to-warc-files-and-urls-in-columnar-format/\n",
      "https://arxiv.org/pdf/1710.01779.pdf\n",
      "http://www.lrec-conf.org/proceedings/lrec2016/pdf/388_Paper.pdf\n",
      "https://dkpro.github.io/dkpro-c4corpus/\n",
      "https://doi.org/10.1145/3178876.3186090\n",
      "http://www.lrec-conf.org/proceedings/lrec2014/pdf/1097_Paper.pdf\n",
      "http://statmt.org/ngrams/\n",
      "https://fulmicoton.com/posts/commoncrawl/\n",
      "https://education.emc.com/content/dam/dell-emc/documents/en-us/2017KS_Ravinder-Using_Open_Data_to_Predict_Market_Movements.pdf\n",
      "http://webdatacommons.org/structureddata/\n",
      "https://aws.amazon.com/cli/\n",
      "https://github.com/awslabs/open-data-registry/blob/master/datasets/commoncrawl.yaml\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "store = []\n",
    "\n",
    "html = urllib.request.urlopen(' http://aws.amazon.com/datasets/41740').read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "data = soup('a')\n",
    "for tag in data:\n",
    "    print(tag.get('href', None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
